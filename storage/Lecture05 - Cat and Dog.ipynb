{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://www.anadronestarting.com/wp-content/uploads/intel-main_opt.png' width=50%>\n",
    "\n",
    "# 모바일넷을 이용한 이미지분류 - 개 / 고양이 분류하기\n",
    "<font size=5><b>(Image Classification using Mobilenet)<b></font>\n",
    "\n",
    "<div align='right'>성  민  석<br>(Minsuk Sung)</div>\n",
    "\n",
    "<img src='https://storage.googleapis.com/kaggle-competitions/kaggle/3362/media/woof_meow.jpg' width=60%>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>강의목차<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#필요한-라이브러리-및-옵션\" data-toc-modified-id=\"필요한-라이브러리-및-옵션-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>필요한 라이브러리 및 옵션</a></span><ul class=\"toc-item\"><li><span><a href=\"#기본-라이브러리(Library)\" data-toc-modified-id=\"기본-라이브러리(Library)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>기본 라이브러리(Library)</a></span></li><li><span><a href=\"#옵션(Option)\" data-toc-modified-id=\"옵션(Option)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>옵션(Option)</a></span></li></ul></li><li><span><a href=\"#예제---개,-고양이-분류하기\" data-toc-modified-id=\"예제---개,-고양이-분류하기-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>예제 - 개, 고양이 분류하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#데이터-불러올-준비\" data-toc-modified-id=\"데이터-불러올-준비-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>데이터 불러올 준비</a></span></li><li><span><a href=\"#데이터-불러오기\" data-toc-modified-id=\"데이터-불러오기-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>데이터 불러오기</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-/-Validation-데이터셋-구성하기\" data-toc-modified-id=\"Train-/-Validation-데이터셋-구성하기-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Train / Validation 데이터셋 구성하기</a></span></li></ul></li><li><span><a href=\"#데이터-살펴보기\" data-toc-modified-id=\"데이터-살펴보기-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>데이터 살펴보기</a></span></li><li><span><a href=\"#모델링\" data-toc-modified-id=\"모델링-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>모델링</a></span><ul class=\"toc-item\"><li><span><a href=\"#VGG16-모델-생성\" data-toc-modified-id=\"VGG16-모델-생성-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>VGG16 모델 생성</a></span></li><li><span><a href=\"#VGG-16-미세-조정\" data-toc-modified-id=\"VGG-16-미세-조정-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>VGG-16 미세 조정</a></span></li><li><span><a href=\"#모델-생성\" data-toc-modified-id=\"모델-생성-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>모델 생성</a></span></li><li><span><a href=\"#모델-컴파일하기\" data-toc-modified-id=\"모델-컴파일하기-2.4.4\"><span class=\"toc-item-num\">2.4.4&nbsp;&nbsp;</span>모델 컴파일하기</a></span></li><li><span><a href=\"#모델-확인\" data-toc-modified-id=\"모델-확인-2.4.5\"><span class=\"toc-item-num\">2.4.5&nbsp;&nbsp;</span>모델 확인</a></span></li></ul></li><li><span><a href=\"#모델-학습하기\" data-toc-modified-id=\"모델-학습하기-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>모델 학습하기</a></span></li><li><span><a href=\"#모델-평가하기\" data-toc-modified-id=\"모델-평가하기-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>모델 평가하기</a></span></li><li><span><a href=\"#모델-검증하기\" data-toc-modified-id=\"모델-검증하기-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>모델 검증하기</a></span></li><li><span><a href=\"#다음-예제에서는\" data-toc-modified-id=\"다음-예제에서는-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>다음 예제에서는</a></span></li></ul></li><li><span><a href=\"#참고\" data-toc-modified-id=\"참고-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>참고</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 필요한 라이브러리 및 옵션\n",
    "\n",
    "### 기본 라이브러리(Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:34.715938Z",
     "start_time": "2019-11-05T17:34:34.706893Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:35.188816Z",
     "start_time": "2019-11-05T17:34:34.718168Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:35.350628Z",
     "start_time": "2019-11-05T17:34:35.190137Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "from IPython.display import SVG\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import Element, ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.084679Z",
     "start_time": "2019-11-05T17:34:35.351647Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist,cifar10\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet, MobileNetV2,VGG16\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Conv2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 옵션(Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.189529Z",
     "start_time": "2019-11-05T17:34:36.085785Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7593625460755922777\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7079893550407942264\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "%matplotlib inline\n",
    "print(device_lib.list_local_devices())\n",
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 예제 - 개, 고양이 분류하기\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/7/7c/Kaggle_logo.png)\n",
    "\n",
    "캐글(Kaggle)에 대해 쉽게 말하자면, 어떤 기업에 방대한 양의 데이터(빅데이터)가 쌓여있다고 생각해보자. 기업에서 이 자료들을 바탕으로 필요한 정보 또는 알고리즘을 알아내기를 원할 때 이를 분석할 전문가가 부족하거나 없는 경우가 태반이다.\n",
    "\n",
    "이때 바로 캐글이 필요하다. 기업이 캐글에게 빅데이터를 제공해주고 캐글은 이를 온라인에 공개하여 세계 각지의 수많은 데이터 과학자들로 하여금 이 문제를 팀이나 개인으로 해결할 수 있도록 한다. 즉, 캐글은 세계 최대 데이터 과학자 커뮤니티인 셈이다.\n",
    "\n",
    "출처 : [네이버 블로그](http://blog.naver.com/PostView.nhn?blogId=suresofttech&logNo=221386791684&categoryNo=100&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=search&userTopListOpen=true&userTopListCount=5&userTopListManageOpen=false&userTopListCurrentPage=1)\n",
    "\n",
    "그 중에서도 우리는 MNIST 데이터셋보다는 조금 더 난이도가 있는 `개 / 고양이` 분류하기 컴피티션을 통해서 CNN 모델 구성을 해보자.\n",
    "\n",
    "대회 사이트 : https://www.kaggle.com/uysimty/keras-cnn-dog-or-cat-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러올 준비\n",
    "\n",
    "MNIST 데이터와 달리, Kaggle 에서 제공한 데이터이기 때문에 따로 파일의 경로를 설정해줘야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.203629Z",
     "start_time": "2019-11-05T17:34:36.190609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터의 크기 : 20000\n",
      "Test 데이터의 크기 : 5000\n"
     ]
    }
   ],
   "source": [
    "# 준비된 데이터셋의 클래스 종류 : 2가지\n",
    "CATDOG_CLASSES = ['cat','dog']\n",
    "\n",
    "# Train / Test 데이터가 저장되어 있는 Path\n",
    "TRAIN_FILE_PATH = './data/Cat-Dog/train/'\n",
    "TEST_FILE_PATH = './data/Cat-Dog/test/'\n",
    "\n",
    "# Train / Test 데이터의 목록\n",
    "TRAIN_LIST = os.listdir(TRAIN_FILE_PATH)\n",
    "TEST_LIST = os.listdir(TEST_FILE_PATH)\n",
    "\n",
    "print('Train 데이터의 크기 : {}'.format(len(TRAIN_LIST)))\n",
    "print('Test 데이터의 크기 : {}'.format(len(TEST_LIST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.207624Z",
     "start_time": "2019-11-05T17:34:36.205216Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 15\n",
    "\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_CHANNELS = 3\n",
    "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "INPUT_SHAPE = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train / Validation 데이터셋 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.224072Z",
     "start_time": "2019-11-05T17:34:36.209143Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습할 Train / Validation 파일 리스트\n",
    "df_list = list()\n",
    "\n",
    "# 데이터 목록 준비하기\n",
    "for data_list in [TRAIN_LIST,TEST_LIST]:\n",
    "    categories = list()\n",
    "    for filename in data_list:\n",
    "        category = filename.split('.')[0]\n",
    "        if category == 'dog': # 개일 경우\n",
    "            categories.append(category)\n",
    "        else:\n",
    "            categories.append(category)\n",
    "\n",
    "    # 각 파일별로 라벨링하기\n",
    "    df = pd.DataFrame({\n",
    "        'filename': data_list,\n",
    "        'category': categories\n",
    "    })\n",
    "    \n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.233137Z",
     "start_time": "2019-11-05T17:34:36.225119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.2612.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.221.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat.10432.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.9166.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat.9300.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat.10965.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat.9297.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.7187.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.6977.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.6816.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category       filename\n",
       "0      dog   dog.2612.jpg\n",
       "1      dog    dog.221.jpg\n",
       "2      cat  cat.10432.jpg\n",
       "3      dog   dog.9166.jpg\n",
       "4      cat   cat.9300.jpg\n",
       "5      cat  cat.10965.jpg\n",
       "6      cat   cat.9297.jpg\n",
       "7      dog   dog.7187.jpg\n",
       "8      dog   dog.6977.jpg\n",
       "9      dog   dog.6816.jpg"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train 데이터 목록 확인하기\n",
    "df_list[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.239096Z",
     "start_time": "2019-11-05T17:34:36.234155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat.10768.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.11325.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.6220.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.9556.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.6287.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat.1885.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.7521.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat.3354.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.5943.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog.8632.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category       filename\n",
       "0      cat  cat.10768.jpg\n",
       "1      dog  dog.11325.jpg\n",
       "2      dog   dog.6220.jpg\n",
       "3      dog   dog.9556.jpg\n",
       "4      dog   dog.6287.jpg\n",
       "5      cat   cat.1885.jpg\n",
       "6      dog   dog.7521.jpg\n",
       "7      cat   cat.3354.jpg\n",
       "8      dog   dog.5943.jpg\n",
       "9      dog   dog.8632.jpg"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터 목록 확인하기\n",
    "df_list[1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.246485Z",
     "start_time": "2019-11-05T17:34:36.240095Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train / Validation 데이터 준비하기\n",
    "train_df, valid_df = train_test_split(df_list[0], test_size=0.20, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "\n",
    "# Test 데이터 준비하기\n",
    "test_df = df_list[1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.341234Z",
     "start_time": "2019-11-05T17:34:36.247462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Train 데이터를 가져오는 ImageDataGenerator 객체 생성\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "# Train 데이터를 가져올 때 DataFrame을 이용\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    TRAIN_FILE_PATH,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.370857Z",
     "start_time": "2019-11-05T17:34:36.342314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Validation 데이터를 가져오는 ImageDataGenerator 객체 생성\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Validation 데이터를 가져올 때 DataFrame을 이용\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    valid_df,\n",
    "    TRAIN_FILE_PATH,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.404889Z",
     "start_time": "2019-11-05T17:34:36.371957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test 데이터를 가져오는 ImageDataGenerator 객체 생성\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Test 데이터를 가져올 때 DataFrame을 이용\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    TEST_FILE_PATH,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:36.408056Z",
     "start_time": "2019-11-05T17:34:36.405894Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train / Validation / Test 크기\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = valid_df.shape[0]\n",
    "total_test = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:37.985181Z",
     "start_time": "2019-11-05T17:34:36.409026Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'random' has no attribute 'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a733567050ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 랜덤으로 Test 데이터에서 데이터 가져오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 추출한 Test 데이터 시각화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'random' has no attribute 'choices'"
     ]
    }
   ],
   "source": [
    "# 랜덤시드 고정\n",
    "np.random.seed(123)\n",
    "\n",
    "# Test 데이터의 데이터 목록\n",
    "flist = glob.glob(TRAIN_FILE_PATH+'*.jpg')\n",
    "\n",
    "# 랜덤으로 Test 데이터에서 데이터 가져오기\n",
    "samples = random.choices(population=range(0, len(train_df)), k=16)\n",
    "\n",
    "# 추출한 Test 데이터 시각화\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 각 Test 데이터 시각화\n",
    "for count, n in enumerate(samples, start=1):\n",
    "    plt.subplot(4, 4, count)\n",
    "    flabel = os.path.basename(flist[n]).split('.')[0]\n",
    "    img = cv2.imread(flist[n])\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB).astype('float32') / 255\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    tmp = \"Label:\" + flabel\n",
    "    plt.title(tmp)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링\n",
    "\n",
    " 앞선 예제에서는 직접 CNN 모델을 구성하여 학습을 진행하였지만, 이번 예제에서는 VGGNet, ResNet, MobileNet과 같이 보편적으로 성능이 좋다고 알려져있는 CNN 모델을 사용해보자. Keras에서는 application 모듈에서 Pretrained된 모델을 사용할 수 있다. 이미지 분류에 사용할 수 있는 모델의 목록은 아래와 같다.\n",
    " \n",
    "- Xception\n",
    "- VGG16\n",
    "- VGG19\n",
    "- ResNet, ResNetV2\n",
    "- InceptionV3\n",
    "- InceptionResNetV2\n",
    "- MobileNet\n",
    "- MobileNetV2\n",
    "- DenseNet\n",
    "- NASNet\n",
    "\n",
    "이번 예제에서는 **`VGG-16`을 사용**해보도록 하자.\n",
    "\n",
    "<img src='https://neurohive.io/wp-content/uploads/2018/11/vgg16.png' width=80%>\n",
    "\n",
    "출처 : [Keras Documentation](https://keras.io/applications/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG16 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:38.829081Z",
     "start_time": "2019-11-05T17:34:37.986341Z"
    }
   },
   "outputs": [],
   "source": [
    "# VGG16 객체 생성\n",
    "base_model = VGG16(input_shape=INPUT_SHAPE,  # CIFAR-10의 이미지 형태\n",
    "                   include_top=False,  # FC Layer를 제거\n",
    "                   weights='imagenet')\n",
    "\n",
    "# VGG16의 모든 Layer를 학습가능하게\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG-16 미세 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:38.835146Z",
     "start_time": "2019-11-05T17:34:38.830145Z"
    }
   },
   "outputs": [],
   "source": [
    "# VGG-16의 상단 Layer를 학습가능여부\n",
    "set_trainable = False\n",
    "\n",
    "# block5_conv1 라는 이름의 Layer를 만나면 학습가능하게끔\n",
    "for layer in tqdm(base_model.layers):\n",
    "    if layer.name in ['block4_conv3','block5_conv3']:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:38.844267Z",
     "start_time": "2019-11-05T17:34:38.836109Z"
    }
   },
   "outputs": [],
   "source": [
    "layers = [(layer, layer.name, layer.trainable) for layer in base_model.layers]\n",
    "\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:38.901087Z",
     "start_time": "2019-11-05T17:34:38.845520Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(base_model) # VGG-16 추가\n",
    "model.add(GlobalAveragePooling2D()) # Transfer Learning을 진행할때 항상 GAP Layer 추가\n",
    "\n",
    "model.add(Dense(len(CATDOG_CLASSES), activation='softmax')) # 분류할 FC Layer 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 컴파일하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:38.942712Z",
     "start_time": "2019-11-05T17:34:38.902178Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy, \n",
    "              optimizer=Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:34:39.015770Z",
     "start_time": "2019-11-05T17:34:38.944583Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "plot_model(model, to_file='./img/model/cat_dog_vgg16.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:46:07.442170Z",
     "start_time": "2019-11-05T17:34:39.017075Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습하기\n",
    "# ImageDataGenerator이기 때문에 fit_generator로 학습을 진행해야함\n",
    "history = model.fit_generator(\n",
    "    train_generator,  \n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//BATCH_SIZE,\n",
    "    steps_per_epoch=total_train//BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:46:07.611028Z",
     "start_time": "2019-11-05T17:46:07.444928Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습한 모델 저장하기\n",
    "model.save('./bin/cat_dog_vgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:47:16.323344Z",
     "start_time": "2019-11-05T17:46:07.612182Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train 데이터에 대한 Loss와 Accuracy\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator,verbose=0)\n",
    "print('Train Loss : {}'.format(train_loss))\n",
    "print('Train Accuracy : {}'.format(train_acc))\n",
    "\n",
    "# Validation 데이터에 대한 Loss와 Accuracy\n",
    "validation_loss, validation_acc = model.evaluate_generator(validation_generator,verbose=0)\n",
    "print('Test Loss : {}'.format(validation_loss))\n",
    "print('Test Accuracy : {}'.format(validation_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:47:16.495391Z",
     "start_time": "2019-11-05T17:47:16.328736Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train / Validation 데이터에 대한 Loss\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(loss)+1)\n",
    "\n",
    "plt.plot(epochs,loss,label='Training Loss')\n",
    "plt.plot(epochs,val_loss,label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:47:16.619453Z",
     "start_time": "2019-11-05T17:47:16.496412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train / Validation 데이터에 대한 Accuracy\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(1,len(loss)+1)\n",
    "\n",
    "plt.plot(epochs,acc,label='Training Accuarcy')\n",
    "plt.plot(epochs,val_acc,label='Validation Accuarcy')\n",
    "plt.title('Training and Validation Accuarcy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuarcy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:50:24.170246Z",
     "start_time": "2019-11-05T17:50:15.219729Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('Test Loss : {}'.format(test_loss))\n",
    "print('Test Accuracy : {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T17:56:30.862529Z",
     "start_time": "2019-11-05T17:56:29.058826Z"
    }
   },
   "outputs": [],
   "source": [
    "# 재연성을 위하여 랜덤시드 고정\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Test 데이터 예측하기\n",
    "predicted_result = model.predict_generator(test_generator,steps=10)\n",
    "\n",
    "# 예측한 데이터의 Label 가져오기\n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "# Test 데이터의 데이터 목록\n",
    "flist = glob.glob(TEST_FILE_PATH+'*.jpg')\n",
    "\n",
    "# 랜덤으로 Test 데이터에서 데이터 가져오기\n",
    "samples = np.random.randint(low= 0, high=len(predicted_labels), size=16)\n",
    "\n",
    "# 추출한 Test 데이터 시각화\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 각 Test 데이터 시각화\n",
    "for count, n in enumerate(samples, start=1):\n",
    "    plt.subplot(4, 4, count)\n",
    "    flabel = os.path.basename(flist[n]).split('.')[0]\n",
    "    img = cv2.imread(flist[n])\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB).astype('float32') / 255\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    tmp = \"Label:\" + flabel + \", Prediction:\" + \\\n",
    "        CATDOG_CLASSES[predicted_labels[n]]\n",
    "    plt.title(tmp)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./img/cat_dog_wrong_result.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다음 예제에서는\n",
    "\n",
    "![](https://miro.medium.com/max/5250/1*n16lj3lSkz2miMc_5cvkrA.jpeg)\n",
    "\n",
    "VGG16을 통해서 이제는 개와 고양이의 클래스를 가진 RGB 이미지에 대해서도 훌륭히 이미지 분류가 되는 것을 확인할 수 있다. 하지만 여전히 한가지 문제점은 VGG16은 엄청난 파라미터 때문에(이번 예제에서 학습만 파라미터만 14,602,954개) NUC와 같은 디바이스에서는 학습이 더디게 진행될 수 있다는 점이다. 그래서 다음 예제에서는 ResNet을 통하여 파라미터를 더 줄이면서 더 많은 클래스를 분류하는 예제를 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intel\n",
    "    - https://www.intel.co.kr/\n",
    "- Intel OpenVINO\n",
    "    - https://software.intel.com/en-us/openvino-toolkit\n",
    "- MNIST\n",
    "    - http://yann.lecun.com/exdb/mnist/\n",
    "- CIFAR10\n",
    "    - https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "- ImageNet\n",
    "    - http://www.image-net.org\n",
    "- Tensorflow\n",
    "    - https://www.tensorflow.org/?hl=ko\n",
    "- Keras\n",
    "    - https://keras.io/\n",
    "    - https://tensorflow.blog/2019/03/06/tensorflow-2-0-keras-api-overview/\n",
    "    - https://tykimos.github.io/2017/02/22/Integrating_Keras_and_TensorFlow/\n",
    "    - https://tykimos.github.io/2017/03/08/CNN_Getting_Started/\n",
    "    - https://raw.githubusercontent.com/keras-team/keras-docs-ko/master/sources/why-use-keras.md\n",
    "- Keras to Caffe\n",
    "     - https://github.com/uhfband/keras2caffe\n",
    "     - http://www.deepvisionconsulting.com/from-keras-to-caffe/\n",
    "- Fully Connected Layer\n",
    "    - https://sonofgodcom.wordpress.com/2018/12/31/cnn%EC%9D%84-%EC%9D%B4%ED%95%B4%ED%95%B4%EB%B3%B4%EC%9E%90-fully-connected-layer%EB%8A%94-%EB%AD%94%EA%B0%80/\n",
    "- Convultional Nueral Network\n",
    "    - http://aikorea.org/cs231n/convolutional-networks/\n",
    "    - http://cs231n.stanford.edu/\n",
    "- CNN Models\n",
    "    - https://ratsgo.github.io/deep%20learning/2017/10/09/CNNs/\n",
    "\n",
    "- VOC2012\n",
    "    - https://blog.godatadriven.com/rod-keras-multi-label\n",
    "    - https://gist.github.com/rragundez/ae3a17428bfec631d1b35dcdc6296a85#file-multi-label_classification_with_keras_imagedatagenerator-ipynbhttps://fairyonice.github.io/Part_5_Object_Detection_with_Yolo_using_VOC_2012_data_training.html\n",
    "    - http://research.sualab.com/introduction/2017/11/29/image-recognition-overview-1.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "강의목차",
   "title_sidebar": "강의목차",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
